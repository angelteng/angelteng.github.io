<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="">
<head><meta name="generator" content="Hexo 3.8.0">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/blog/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/blog/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/blog/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/blog/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/blog/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/blog/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/blog/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">










<meta property="og:type" content="website">
<meta property="og:title" content="Code war of Angel">
<meta property="og:url" content="https://angelteng.github.io/blog/page/3/index.html">
<meta property="og:site_name" content="Code war of Angel">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Code war of Angel">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/blog/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://angelteng.github.io/blog/page/3/">





  <title>Code war of Angel</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  








</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/blog/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Code war of Angel</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/blog/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/blog/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://angelteng.github.io/blog/blog/2019/05/27/降维算法/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Angel Teng">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://angelteng.github.io/blog/images/angel.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Code war of Angel">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/blog/2019/05/27/降维算法/" itemprop="url">降维算法</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-05-27T16:33:20+08:00">
                2019-05-27
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/blog/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <ol>
<li>降维算法中的”降维“，指的是降低特征矩阵中特征的数量。</li>
<li><p>in sklearn<br><img src="0.png" alt="image.png"></p>
</li>
<li><p>PCA使用的信息量衡量指标，就是样本方差，又称可解释性方差，方差越大，特征所带的信息量越多。<br><img src="1.png" alt="image.png"><br>Var代表一个特征的方差，n代表样本量，xi代表一个特征中的每个样本取值，xhat代表这一列样本的均值。</p>
<ul>
<li><a href="https://www.zhihu.com/question/20099757" target="_blank" rel="noopener">为什么方差的分母是n-1？</a></li>
</ul>
</li>
<li><p>矩阵分解：让数据能够被压缩到少数特征上并且总信息量不损失太多的技术。PCA和SVD是两种不同的降维算法，只是两种算法中矩阵分解的方法不同，信息量的衡量指标不同罢了。降维完成之后，PCA找到的每个新特征向量就叫做“主成分”，而被丢弃的特征 向量被认为信息量很少，这些信息很可能就是噪音。</p>
<ul>
<li>PCA使用方差作为信息量的衡量指标，并且特征值分解来找出空间V。</li>
<li>SVD使用奇异值分解来找出空间V</li>
</ul>
</li>
<li><p>降维与特征工程的区别：</p>
<ul>
<li>特征选择是从已存在的特征中选取携带信息最多的，选完之后的特征依然具有可解释性，我们依然知道这个特征在原数据的哪个位置，代表着原数据上的什么含义。</li>
<li>降维算法，是将已存在的特征进行压缩，降维完毕后的特征不是原本的特征矩阵中的任何一个特征，而是通过某些方式组合起来的新特征。通常来说，在新的特征矩阵生成之前，我们无法知晓降维算法们都建立了怎样 的新特征向量，新特征矩阵生成之后也不具有可读性，我们无法判断新特征矩阵的特征是从原数据中的什么特征组合而来，新特征虽然带有原始数据的信息，却已经不是原数据上代表着的含义了。降维算法因此是特征创造(feature creation，或feature construction)的一种。</li>
<li>可以想见，PCA一般不适用于探索特征和标签之间的关系的模型(如线性回归)，因为无法解释的新特征和标签之间的关系不具有意义。在线性回归模型中，我们使用特征选择。</li>
</ul>
</li>
<li><p>sklearn.decomposition.PCA (n_components=None, copy=True, whiten=False, svd_solver=’auto’, tol=0.0， iterated_power=’auto’, random_state=None)</p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.decomposition import PCA</span><br><span class="line">#调用PCA</span><br><span class="line">pca = PCA(n_components=2) pca = pca.fit(X)</span><br><span class="line">X_dr = pca.transform(X)</span><br><span class="line"># 属性explained_variance，查看降维后每个新特征向量上所带的信息量大小(可解释性方差的大小) </span><br><span class="line">pca.explained_variance_</span><br><span class="line"># 属性explained_variance_ratio，查看降维后每个新特征向量所占的信息量占原始数据总信息量的百分比 </span><br><span class="line"># 又叫做可解释方差贡献率</span><br><span class="line">pca.explained_variance_ratio_</span><br><span class="line"># 降维后的总方差为原来方差的百分比</span><br><span class="line">pca.explained_variance_ratio_.sum()</span><br></pre></td></tr></table></figure>
<p> 参数：</p>
<ul>
<li>n_components: n_components是我们降维后需要的维度，即降维后需要保留的特征数量，降维流程中第二步里需要确认的k值，一般输入[0, min(X.shape)]范围中的整数。</li>
<li>svd_solver: 奇异值分解器。sklearn将降 维流程拆成了两部分:一部分是计算特征空间V，由奇异值分解完成，另一部分是映射数据和求解新特征矩阵，由主成分分析完成，实现了用SVD的性质减少计算量，却让信息量的评估指标是方差，具体流程如下图:</li>
<li>random_state<br>接口：</li>
<li>inverse_transform </li>
</ul>
</li>
<li><p>选择最好的n_components:</p>
<ul>
<li><p>方法一：累积可解释方差贡献率曲线，选择拐点作为最优参数值</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">pca_line = PCA().fit(X) plt.plot([1,2,3,4],np.cumsum(pca_line.explained_variance_ratio_)) </span><br><span class="line">plt.xticks([1,2,3,4]) #这是为了限制坐标轴显示为整数</span><br><span class="line">plt.xlabel(&quot;number of components after dimension reduction&quot;) </span><br><span class="line">plt.ylabel(&quot;cumulative explained variance&quot;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
</li>
<li><p>方法二：最大似然估计自选超参数法</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pca_mle = PCA(n_components=&quot;mle&quot;)</span><br></pre></td></tr></table></figure>
</li>
<li><p>方法三：按信息量占比选超参数<br>输入[0,1]之间的浮点数，并且让参数svd_solver ==’full’，表示希望降维后的总解释性方差占比大于n_components 指定的百分比，即是说，希望保留百分之多少的信息量。比如说，如果我们希望保留97%的信息量，就可以输入 n_components = 0.97，PCA会自动选出能够让保留的信息量超过97%的特征数量。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pca_f = PCA(n_components=0.97,svd_solver=&quot;full&quot;)</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://angelteng.github.io/blog/blog/2019/05/27/特征工程-embedded嵌入法/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Angel Teng">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://angelteng.github.io/blog/images/angel.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Code war of Angel">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/blog/2019/05/27/特征工程-embedded嵌入法/" itemprop="url">特征工程_embedded嵌入法与包装法</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-05-27T11:19:56+08:00">
                2019-05-27
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/blog/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="嵌入法"><a href="#嵌入法" class="headerlink" title="嵌入法"></a>嵌入法</h1><ol>
<li><p>嵌入法是一种让算法自己决定使用哪些特征的方法，即特征选择和算法训练同时进行。在使用嵌入法时，我们先使用某些机器学习的算法和模型进行训练，得到各个特征的权值系数，根据权值系数从大到小选择特征。并且，由于考虑特征对模型的贡献，因此无关的特征（需要相关性过滤的特征）和无区分度的特征（需要方差过滤的特征）都会因为缺乏对模型的贡献而被删除掉，可谓是过滤法的进化版。<br><img src="0.png" alt="image.png"></p>
</li>
<li><p>sklearn.feature_selection.SelectFromModel (estimator, threshold=None, prefit=False, norm_order=1,<br>max_features=None)</p>
<ul>
<li>estimator　　　　　　　　<br>  使用的模型评估器，只要是带feature_importances_或者coef_属性，或带有l1和l2惩罚项的模型都可以使用</li>
<li>threshold<br>  特征重要性的阈值，重要性低于这个阈值的特征都将被删除</li>
<li>prefit<br>  默认False，判断是否将实例化后的模型直接传递给构造函数。如果为True，则必须直接调用fit和transform，不能使用fit_transform，并且SelectFromModel不能与cross_val_score，GridSearchCV和克隆估计器的类似实用程序一起使用。</li>
<li>norm_order<br>  k可输入非零整数，正无穷，负无穷，默认值为1<br>  在评估器的coef_属性高于一维的情况下，用于过滤低于阈值的系数的向量的范数的阶数</li>
<li><p>max_features<br>  在阈值设定下，要选择的最大特征数。要禁用阈值并仅根据max_features选择，请设置threshold = -np.inf</p>
<p>随机森林中的应用：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.feature_selection import SelectFromModel</span><br><span class="line">from sklearn.ensemble import RandomForestClassifier as RFC</span><br><span class="line">RFC_ = RFC(n_estimators =10,random_state=0)</span><br><span class="line">X_embedded = SelectFromModel(RFC_,threshold=0.005).fit_transform(X,y)</span><br><span class="line"># 可以使用学习曲线确认threshold最佳值</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>在嵌入法下，我们很容易就能够实现特征选择的目标：减少计算量，提升模型表现。因此，比起要思考很多统计量的过滤法来说，嵌入法可能是更有效的一种方法。然而，在算法本身很复杂的时候，过滤法的计算远远比嵌入法要快，所以大型数据中，我们还是会优先考虑过滤法。</p>
</li>
</ol>
<p>参考：<br><a href="https://www.cnblogs.com/zhange000/articles/10751525.html" target="_blank" rel="noopener">特征选择-嵌入</a></p>
<h1 id="包装法"><a href="#包装法" class="headerlink" title="包装法"></a>包装法</h1><p>包装法，根据目标函数（通常是预测效果评分），每次选择若干特征，或者排除若干特征。</p>
<ol>
<li>递归特征消除法<br> 递归消除特征法使用一个基模型来进行多轮训练，每轮训练后，消除若干权值系数的特征，再基于新的特征集进行下一轮训练。 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.feature_selection import RFE</span><br><span class="line">from sklearn.linear_model import LogisticRegression</span><br><span class="line"></span><br><span class="line">#递归特征消除法，返回特征选择后的数据</span><br><span class="line">#参数estimator为基模型</span><br><span class="line">#参数n_features_to_select为选择的特征个数</span><br><span class="line">RFE(estimator=LogisticRegression(), n_features_to_select=2).fit_transform(iris.data,iris.target)</span><br></pre></td></tr></table></figure>
</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://angelteng.github.io/blog/blog/2019/05/24/特征工程_Filter过滤法/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Angel Teng">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://angelteng.github.io/blog/images/angel.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Code war of Angel">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/blog/2019/05/24/特征工程_Filter过滤法/" itemprop="url">特征工程_Filter过滤法</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-05-24T17:36:09+08:00">
                2019-05-24
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/blog/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <ol>
<li><p>流程</p>
<ul>
<li>特征提取</li>
<li>特征创造</li>
<li>特征选择：过滤-&gt;嵌入/包装/降维</li>
</ul>
</li>
<li><p>Filter过滤法</p>
<ol>
<li><p>方差过滤<br> 这是通过特征本身的方差来筛选特征的类。比如一个特征本身的方差很小，就表示样本在这个特征上基本没有差异，可能特征中的大多数值都一样，甚至整个特征的取值都相同，那这个特征对于样本区分没有什么作用。所以无论接下来的特征工程要做什么，都要优先消除方差为0的特征。</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.feature_selection import VarianceThreshold</span><br><span class="line">selector = VarianceThreshold(threshold=0) #阈值，抛弃所有低于阈值的特征</span><br><span class="line">X_var0 = selector.fit_transform(X)</span><br></pre></td></tr></table></figure>
<p> 影响：最近邻算法KNN，单棵决策树，支持向量机SVM，神经网络，回归算法，都需要遍历特征或升维来进行运算，所以他们本身的运算量就很大，需要的时间就很长，因此方差过滤这样的特征选择对他们来说就尤为重要。但对于不需要遍历特征的算法，比如随机森林，它随机选取特征进行分枝，本身运算就非常快速，因此特征选择对它来说效果平平。</p>
</li>
<li><p>相关性过滤</p>
<ol>
<li><p>卡方过滤</p>
<ul>
<li>卡方过滤是专门针对离散型标签（即分类问题）的相关性过滤。</li>
<li><p>卡方检验类feature_selection.chi2计算每个非负特征和标签之间的卡方统计量，并依照卡方统计量由高到低为特征排名。再结合feature_selection.SelectKBest这个可以输入”评分标准“来选出前K个分数最高的特征的类。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.feature_selection import SelectKBest</span><br><span class="line">from sklearn.feature_selection import chi2</span><br><span class="line">#假设需要300个特征</span><br><span class="line">X_fschi = SelectKBest(chi2, k=300).fit_transform(X_fsvar, y)</span><br></pre></td></tr></table></figure>
</li>
<li><p>定义超参数K的值</p>
<ul>
<li>学习曲线</li>
<li><p>看p值选择K<br>  卡方检验的本质是推测两组数据之间的差异，其检验的原假设是”两组数据是相互独立的”。卡方检验返回卡方值和P值两个统计量，其中卡方值很难界定有效的范围，而p值，我们一般使用0.01或0.05作为显著性水平</p>
<ul>
<li>P&lt;=0.05/0.01: 拒绝原假设，接受备择假设 </li>
<li><p>p&gt;0.05/0.01 : 接受原假设</p>
<p>从特征工程的角度，我们希望选取卡方值很大，p值小于0.05的特征，即和标签是相关联的特征。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">chivalue, pvalues_chi = chi2(X_fsvar,y)</span><br><span class="line"># k取多少？我们想要消除所有p值大于设定值，比如0.05或0.01的特征：</span><br><span class="line">k_ = chivalue.shape[0] - (pvalues_chi &gt; 0.05).sum()</span><br><span class="line">X_fschi = SelectKBest(chi2, k=k_).fit_transform(X_fsvar, y)</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>F检验</p>
<ul>
<li>是用来捕捉每个特征与标签之间的线性关系的过滤方法。它即可以做回归(feature_selection.f_regression)也可以做分类(feature_selection.f_classif)。</li>
<li>和卡方检验一样，这两个类需要和类SelectKBest连用.</li>
<li>F检验在数据服从正态分布时效果会非常稳定，因此如果使用F检验过滤，我们会先将数据转换成服从正态分布的方式。</li>
<li>F检验的本质是寻找两组数据之间的线性关系，其原假设是”数据不存在显著的线性关系“。它返回F值和p值两个统计量。和卡方过滤一样，我们希望选取p值小于0.05或0.01的特征，这些特征与标签时显著线性相关的。<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.feature_selection import f_classif</span><br><span class="line">F, pvalues_f = f_classif(X_fsvar,y)</span><br><span class="line">k_ = F.shape[0] - (pvalues_f &gt; 0.05).sum()</span><br><span class="line">X_fsF = SelectKBest(f_classif, k=k_).fit_transform(X_fsvar, y)</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>互信息法</p>
<ul>
<li>互信息法是用来捕捉每个特征与标签之间的任意关系（包括线性和非线性关系）的过滤方法。和F检验相似，它既可以做回归也可以做分类，并且包含两个类feature_selection.mutual_info_classif（互信息分类）和feature_selection.mutual_info_regression（互信息回归）。</li>
<li>互信息法不返回p值或F值类似的统计量，它返回“每个特征与目标之间的互信息量的估计”，这个估计量在[0,1]之间取值，为0则表示两个变量独立，为1则表示两个变量完全相关。<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.feature_selection import mutual_info_classif as MIC</span><br><span class="line">result = MIC(X_fsvar,y)</span><br><span class="line">k_ = result.shape[0] - sum(result &lt;= 0)</span><br><span class="line">X_fsmic = SelectKBest(MIC, k=k_).fit_transform(X_fsvar, y)</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ol>
</li>
</ol>
</li>
<li><p>总结</p>
</li>
</ol>
<table>
<thead>
<tr>
<th style="text-align:left">参数</th>
<th>说明</th>
<th>超参数配置</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">VarianceThreshold</td>
<td>方差过滤，可输入方差阈值，返回方差大于阈值的新特征矩阵</td>
<td>一般使用0/1筛选，可以画学习曲线</td>
</tr>
<tr>
<td style="text-align:left">SelectKBest</td>
<td>用来选取K个统计量结果最佳的矩阵，生成符合统计量要求的新特征矩阵</td>
<td>看配合使用的统计量</td>
</tr>
<tr>
<td style="text-align:left">chi2</td>
<td>卡方验证，专用于分类算法</td>
<td>追求p小于显著性水平的特征</td>
</tr>
<tr>
<td style="text-align:left">f_classif</td>
<td>F检验分类，只能捕捉线性相关，要求数据服从正态分布</td>
<td>追求p小于显著性水平的特征</td>
</tr>
<tr>
<td style="text-align:left">f_regression</td>
<td>F检验回归，只能捕捉线性相关，要求数据服从正态分布</td>
<td>追求p小于显著性水平的特征</td>
</tr>
<tr>
<td style="text-align:left">mutual_info_classif</td>
<td>互信息分类，可以捕捉任何相关性，不能用于稀疏矩阵</td>
<td>追求互信息大于0的特征</td>
</tr>
<tr>
<td style="text-align:left">mutual_info_regression</td>
<td>互信息回归，可以捕捉任何相关性，不能用于稀疏矩阵</td>
<td>追求互信息大于0的特征</td>
</tr>
</tbody>
</table>
<p> 参考：<br><a href="https://www.cnblogs.com/zhange000/articles/10750903.html" target="_blank" rel="noopener">Filter过滤法</a> </p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://angelteng.github.io/blog/blog/2019/05/24/数据预处理/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Angel Teng">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://angelteng.github.io/blog/images/angel.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Code war of Angel">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/blog/2019/05/24/数据预处理/" itemprop="url">数据预处理</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-05-24T14:51:48+08:00">
                2019-05-24
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/blog/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <ol>
<li><p>数据挖掘的流程</p>
<ul>
<li>获取数据</li>
<li>数据预处理：从数据中检测，纠正或删除损坏，不准确或不适用于模型的记录过程。</li>
<li>特征工程：特征工程是将原始数据转换为更能代表预测模型的潜在问题的特征的过程，可以通过挑选最相关的特征，提取特征以及创造特征来实现。</li>
<li>建模</li>
<li>上线、验证</li>
</ul>
</li>
<li><p>数据无量纲化<br>在机器学习算法实践中，我们往往有着将不同规格的数据转换到同一规格，或不同分布的数据转换到某个特定分布 的需求，这种需求统称为将数据“无量纲化”。</p>
<ul>
<li>线性的无量纲化<ul>
<li>中心化</li>
<li>缩放</li>
</ul>
</li>
<li>非线性的无量纲化</li>
</ul>
<ol>
<li><p>数据归一化（异常值敏感）<br> 当数据(x)按照最小值中心化后，再按极差(最大值 - 最小值)缩放，数据移动了最小值个单位，并且会被收敛到 [0,1]之间。<br> <img src="0.png" alt="image.png"></p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.preprocessing import MinMaxScaler</span><br><span class="line">scaler = MinMaxScaler(feature_range=[5,10])   # scaler后5~10之间，默认 0~1</span><br><span class="line">result = scaler.fit(data)</span><br><span class="line">result = scaler.transform(data)</span><br><span class="line"># 一步达成</span><br><span class="line">result_ = scaler.fit_transform(data)</span><br><span class="line"># 逆转</span><br><span class="line">scaler.inverse_transform(result)</span><br></pre></td></tr></table></figure>
</li>
<li><p>数据标准化(优先选用)<br> 当数据(x)按均值(μ)中心化后，再按标准差(σ)缩放，数据就会服从为均值为0，方差为1的正态分布(即标准正态分布)<br> <img src="1.png" alt="image.png"></p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.preprocessing import StandardScaler</span><br><span class="line">scaler = StandardScaler()</span><br><span class="line">scaler.fit(data)</span><br><span class="line">print(scaler.mean_)</span><br><span class="line">print(scaler.var_)</span><br><span class="line">res = scaler.transform(data)</span><br><span class="line">res.mean()</span><br><span class="line">res.std()</span><br></pre></td></tr></table></figure>
</li>
</ol>
</li>
</ol>
<pre><code>![image.png](2.png)
</code></pre><ol start="3">
<li><p>处理缺失值</p>
<ol>
<li><p>impute.SimpleImputer(missing_values=nan, strategy=’mean’, fill_value=None, verbose=0, copy=True)</p>
<ul>
<li>missing_values ：缺失数据的值</li>
<li>strategy：填补策略<ul>
<li>mean：均值填补(仅对数值型特征可用) </li>
<li>median：中值填补(仅对数值型特征可用) </li>
<li>most_frequent：众数填补(对数值型和字符型特征都可用) </li>
<li>constant：参考参数“fill_value”中的值(对数值型和字符型特征都可用)</li>
</ul>
</li>
<li>fill_value：填补值</li>
<li><p>copy： 创建副本</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.impute import SimpleImputer</span><br><span class="line">im = SimpleImputer(strategy=&apos;median&apos;)</span><br><span class="line">im.fit(age)</span><br><span class="line">im.transform(age)</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>使用pandas处理</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data.loc[:,&quot;Age&quot;] = data.loc[:,&quot;Age&quot;].fillna(data.loc[:,&quot;Age&quot;].median())</span><br><span class="line">data.dropna(axis=0,inplace=True) #删除行</span><br></pre></td></tr></table></figure>
</li>
</ol>
</li>
<li><p>处理分类型特征<br> 编码： 文字型数据转化为数字型数据。<br> 哑变量：它是人为虚设的变量，来反映某个变量的相互独立的不同属性。（比如身份：学生、工人、教师）</p>
<ol>
<li><p>preprocessing.LabelEncoder: 标签y专用，将分类转化为分类数值</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.preprocessing import LabelEncoder</span><br><span class="line">y = data.Survived</span><br><span class="line">le = LabelEncoder()</span><br><span class="line">data.Survived=le.fit_transform(y)</span><br></pre></td></tr></table></figure>
</li>
<li><p>preprocessing.LabelBinarizer: 标签y专用，将分类转化为哑变量</p>
</li>
<li><p>preprocessing.OrdinalEncoder: 特征X专用，将分类特征转化为分类数值 (如果特征的值有关联性，处理有序变量)</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.preprocessing import OrdinalEncoder</span><br><span class="line">x = data.Embarked</span><br><span class="line">le = OrdinalEncoder()</span><br><span class="line">data.Embarked=le.fit_transform(x.values.reshape(-1,1))</span><br></pre></td></tr></table></figure>
</li>
<li><p>preprocessing.OneHotEncoder: 独热编码，创建哑变量 （特征的值无关关联性，处理名义变量）<br> <img src="3.png" alt="image.png"></p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.preprocessing import OneHotEncoder</span><br><span class="line">xs = data.loc[:,[&apos;Sex&apos;,&apos;Embarked&apos;]]</span><br><span class="line">one= OneHotEncoder()</span><br><span class="line">res= one.fit(xs)</span><br><span class="line">columns = res.get_feature_names() #查看类型名称</span><br><span class="line">res= one.transform(xs).toarray() </span><br><span class="line">newdata = pd.concat([data,pd.DataFrame(res,columns=columns)],axis=1)</span><br></pre></td></tr></table></figure>
<p><img src="4.png" alt="image.png"></p>
</li>
</ol>
</li>
<li><p>处理连续性变量<br> 二值化：根据阈值将数据二值化，分为0/1。<br> 分段：连续型变量划分为分类变量的类，能够将连续型变量排序后按顺序分箱后编码。</p>
<ol>
<li><p>preprocessing.Binarizer: 根据阈值将数据二值化</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.preprocessing import Binarizer</span><br><span class="line">x = data2.Age.values.reshape(-1,1)</span><br><span class="line">bins = Binarizer(threshold=30) # 阈值=30</span><br><span class="line">res = bins.fit_transform(x)</span><br></pre></td></tr></table></figure>
</li>
<li><p>preprocessing.KBinsDiscretizer: 将连续性变量排序后分箱<br> 参数：</p>
<pre><code>- n_bins: 每个特征中分箱的个数。默认5。
- encode: 编码方式
    - onehot: 哑变量，返回一个稀疏数组
    - ordinal: 每个特征中每个箱都被编码为一个整数
    - onehot-dense: 哑变量，返回密集数组
- strategy: 定义箱框的方式
    - uniform: 等宽分箱
    - quantile: 等位分箱，每个箱内样本数量相同（默认）
    - kmeans: 按聚类分箱
</code></pre> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.preprocessing import KBinsDiscretizer</span><br><span class="line">X = data.Age.values.reshape(-1,1)</span><br><span class="line">est = KBinsDiscretizer(n_bins=3, encode=&apos;ordinal&apos;, strategy=&apos;uniform&apos;)</span><br><span class="line">est.fit_transform(X)</span><br><span class="line">#查看转换后分的箱:变成了一列中的三箱 set(est.fit_transform(X).ravel())</span><br><span class="line">est = KBinsDiscretizer(n_bins=3, encode=&apos;onehot&apos;, strategy=&apos;uniform&apos;) #查看转换后分的箱:变成了哑变量</span><br><span class="line">est.fit_transform(X).toarray()</span><br></pre></td></tr></table></figure>
</li>
</ol>
</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://angelteng.github.io/blog/blog/2019/05/24/随机森林/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Angel Teng">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://angelteng.github.io/blog/images/angel.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Code war of Angel">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/blog/2019/05/24/随机森林/" itemprop="url">随机森林</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-05-24T10:59:56+08:00">
                2019-05-24
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/blog/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <ol>
<li>随机森林是一种集成算法，集成算法的目标：考虑多个评估器的建模结果，汇总之后得到一个综合的结果，以此来获取比单个模型更好的回归或<br>分类表现。</li>
<li>多个模型集成成为的模型叫做集成评估器(ensemble estimator)，组成集成评估器的每个模型都叫做基评估器 (base estimator)。通常来说，有三类集成算法:装袋法(Bagging)，提升法(Boosting)和stacking。</li>
<li><p>随机森林是一种装袋法模型，装袋法的核心是构建多个独立的评估器，然后对其预测进行平均或多数表决原则决定集成评估器的效果。而提升法中，基评估器是相关的，是按顺序一一构建的。其核心思想是结合弱评估器的力量一次次对难以评估的样本 进行预测，从而构成一个强评估器。提升法的代表模型有Adaboost和梯度提升树。</p>
</li>
<li><p>随机森林的特点：</p>
<ul>
<li>在与其它现有的算法相比，其预测准确率很好</li>
<li>在较大的数据集上计算速度依然很快</li>
<li>不需要降维，算法本身是采取随机降维的</li>
<li>他能处理有缺失值的数据集。算法内部有补缺失值的函数</li>
<li>能给出变量的重要性</li>
<li>能处理imbalanced data set</li>
<li>能给出观测实例间的相似度矩阵，其实就是proximity啦，继而能做clustering 和 location outlier</li>
<li>能对unlabeled data 进行无监督的学习，进行clustering</li>
<li>生成的森林可以保留，应用在新的数据集上</li>
</ul>
</li>
<li><p>控制评估器的参数</p>
<ul>
<li>criterion: 不纯度衡量指标</li>
<li>max_depth: 树最大深度</li>
<li>min_samples_leaf：一个节点在分枝后的每个子节点都必须包含至少min_samples_leaf个训练样本</li>
<li>min_samples_split: 一个分支至少含有min_samples_split个训练样本</li>
<li>max_features： 限制分支时考虑特征个数</li>
<li>min_impurity_decrease: 限制信息增益大小</li>
</ul>
</li>
</ol>
<p>重要参数</p>
<pre><code>- n_estimators： 这是森林中树木的数量，即基基评估器的数量。这个参数对随机森林模型的精确性影响是单调的，n_estimators 越大，模型的效往往越好。但是相应的，任何模型都有决策边界，n_estimators达到一定的程度之后，随机森林 的精确性往往不在上升或开始波动。
</code></pre><p>重要属性</p>
<pre><code>- .estimators_是用来查看随机森林中所有树的列表的。
- oob_score_指的是袋外得分。随机森林为了确保林中的每棵树都不尽相同，所以采用了对训练集进行有放回抽样的 方式来不断组成信的训练集，在这个程中，会有一些数据从来没有被随机挑选到，他们就被叫做“袋外数据”。
- .feature_importances_和决策树中的.feature_importances_用法和含义都一致，是返回特征的重要性。
- predict_proba()： 返回每个测试样本对应的被分到每一类标签的概率
</code></pre><ol start="6">
<li><p>在sklearn中的使用</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.ensemble import RandomForestClassifier</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
</li>
<li><p>泛化误差<br><img src="0.png" alt="image.png"><br>当模型太复杂，模型就会过拟合，泛化能力就不够，所以泛化误差大。当模型太简单，模型就会欠拟合，拟合能力就不够，所以误差也会大。只有当模型的复杂度刚刚好的才能够达到泛化误差最小的目标。<br>树模型是天生位于图的右上角的模型，随机森林是以树模型为基础，所以随机森林也是天生复杂度高的模型。随机森林的参数，都是向着一个目标去:减少模型的复杂度，把模型往图像的左边移动，防止过拟合。</p>
</li>
<li><p>参数对误差的影响</p>
</li>
</ol>
<table>
<thead>
<tr>
<th style="text-align:left">参数</th>
<th style="text-align:left">影响</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">n_estimators</td>
<td style="text-align:left">提升至平稳，n_estimators↑，不影响单个模型的复杂度</td>
</tr>
<tr>
<td style="text-align:left">max_depth</td>
<td style="text-align:left">有增有减，默认最大深度，即最高复杂度</td>
</tr>
<tr>
<td style="text-align:left">min_samples_leaf</td>
<td style="text-align:left">有增有减，默认最小限制1，即最高复杂度</td>
</tr>
<tr>
<td style="text-align:left">min_samples_split</td>
<td style="text-align:left">有增有减，默认最小限制2，即最高复杂度</td>
</tr>
<tr>
<td style="text-align:left">max_features</td>
<td style="text-align:left">有增有减，默认auto，是特征总数的开平方，位于中间复杂度，max_features↓，模型更简单</td>
</tr>
<tr>
<td style="text-align:left">criterion</td>
<td style="text-align:left">有增有减，一般使用gini</td>
</tr>
</tbody>
</table>
<ol start="9">
<li><p>调参</p>
<ul>
<li><p>学习曲线</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.model_selection import cross_val_score</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">scorel = []</span><br><span class="line">for i in range(0,200,10):</span><br><span class="line">    rfc = RandomForestClassifier(n_estimators=i+1,</span><br><span class="line">                                n_jobs=-1,</span><br><span class="line">                                random_state=90)</span><br><span class="line">    score = cross_val_score(rfc,data.data,data.target,cv=10).mean()</span><br><span class="line">    scorel.append(score)</span><br><span class="line">print(max(scorel),(scorel.index(max(scorel))*10)+1)</span><br><span class="line">plt.figure(figsize=[20,5])</span><br><span class="line">plt.plot(range(1,201,10),scorel)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
</li>
<li><p>网格搜索</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.model_selection import GridSearchCV</span><br><span class="line">param_grid = &#123;&apos;max_depth&apos;:np.arange(1,20,1)&#125;</span><br><span class="line">rfc = RandomForestClassifier(n_estimators=39</span><br><span class="line">                     ,random_state=90</span><br><span class="line">                    )</span><br><span class="line">GS = GridSearchCV(rfc,param_grid,cv=10)</span><br><span class="line">GS.fit(data.data,data.target)</span><br><span class="line">GS.best_params_</span><br><span class="line">GS.best_score_</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ol>
<p>参考：<br><a href="http://edu.cda.cn/course/982/tasks" target="_blank" rel="noopener">菜菜的机器学习sklearn课堂</a><br><a href="http://www.cnblogs.com/litao1105/p/5021747.html" target="_blank" rel="noopener">随机森林算法－Deep Dive</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://angelteng.github.io/blog/blog/2019/05/23/决策树/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Angel Teng">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://angelteng.github.io/blog/images/angel.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Code war of Angel">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/blog/2019/05/23/决策树/" itemprop="url">决策树</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-05-23T17:55:30+08:00">
                2019-05-23
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/blog/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <ol>
<li>决策树算法的核心是要解决两个问题: <ul>
<li>如何从数据表中找出最佳节点和最佳分枝? </li>
<li>如何让决策树停止生长，防止过拟合?</li>
</ul>
</li>
<li>流程：<ul>
<li>计算全部特征的不纯度</li>
<li>选取不纯度指标最优的特征来分化</li>
<li>在第一个特征分支下，计算全部特征不纯度</li>
<li>选取不纯度指标最优的特征继续分化</li>
</ul>
</li>
<li><p>sklearn中使用</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">from sklearn import tree</span><br><span class="line">tree.DecisionTreeClassifier:分类树</span><br><span class="line">tree.DecisionTreeRegressor:回归树</span><br><span class="line">tree.export_graphviz:将生成的决策树导出为DOT格式，画图专用</span><br><span class="line">tree.ExtraTreeClassifier:高随机版本的分类树</span><br><span class="line">tree.ExtraTreeRegressor:高随机版本的回归树</span><br></pre></td></tr></table></figure>
</li>
<li><p>重要参数</p>
<ul>
<li>criterion: 不纯度的计算方法（不纯度越低、拟合效果越好）<ul>
<li>entropy 信息熵</li>
<li>gini    基尼系数（默认）</li>
</ul>
</li>
<li>random_state: 随机模式，高纬度下随机性更明显<ul>
<li>None （默认）</li>
<li>任意整数</li>
</ul>
</li>
<li>splitter： 随机选项<ul>
<li>best： 优先选择更重要的特征进行分支</li>
<li>random： 分支随机（防止过拟合）</li>
</ul>
</li>
</ul>
</li>
<li>剪枝参数<br>在不加限制的情况下，一棵决策树会生长到衡量不纯度的指标最优，或者没有更多的特征可用为止，这样的决策树往往会过拟合。<ul>
<li>max_depth: 限制最大深度</li>
<li>min_samples_leaf：一个节点在分枝后的每个子节点都必须包含至少min_samples_leaf个训练样本</li>
<li>min_samples_split: 一个分支至少含有min_samples_split个训练样本</li>
<li>max_features: 限制分枝时考虑的特征个数 </li>
<li>min_impurity_decrease: 限制信息增益的大小</li>
</ul>
</li>
<li>目标权重参数<ul>
<li>class_weight：均衡标签样本的权重</li>
<li>min_ weight_fraction_leaf：基于权重的剪枝参数</li>
</ul>
</li>
<li>确定最优参数：<ul>
<li>学习曲线</li>
</ul>
</li>
</ol>
<p>参考<br><a href="http://edu.cda.cn/course/982/tasks" target="_blank" rel="noopener">菜菜的机器学习sklearn课堂</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://angelteng.github.io/blog/blog/2019/05/23/机器学习链接/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Angel Teng">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://angelteng.github.io/blog/images/angel.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Code war of Angel">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/blog/2019/05/23/机器学习链接/" itemprop="url">机器学习链接</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-05-23T15:43:22+08:00">
                2019-05-23
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/blog/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>持续更新中….</p>
<ol>
<li>courea上吴恩达的机器学习课程，<a href="https://angelteng.github.io/blog/2019/01/10/机器学习基石学习笔记（一）/">笔记</a></li>
<li><a href="https://wizardforcel.gitbooks.io/pyda-2e/content/14.html" target="_blank" rel="noopener">《利用python进行数据分析》</a>，包含pandas、numpy、matplotlib的使用</li>
<li>sklearn 的使用：<ul>
<li><a href="https://morvanzhou.github.io/tutorials/machine-learning/sklearn/" target="_blank" rel="noopener">通用机器学习 Scikit-learn</a></li>
<li><a href="https://www.bilibili.com/video/av35523476" target="_blank" rel="noopener">菜菜的sklearn课堂</a></li>
</ul>
</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://angelteng.github.io/blog/blog/2019/04/30/tensorflow-Web服务部署的坑/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Angel Teng">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://angelteng.github.io/blog/images/angel.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Code war of Angel">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/blog/2019/04/30/tensorflow-Web服务部署的坑/" itemprop="url">tensorflow Web服务部署的坑</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-04-30T14:13:32+08:00">
                2019-04-30
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="问题场景："><a href="#问题场景：" class="headerlink" title="问题场景："></a>问题场景：</h1><p>由于需要部署一个基于tensorflow的算法Web服务，使用了uwsgi+flask去部署。<br>uwsgi 使用了多进程，参数为：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[uwsgi]</span><br><span class="line">socket = 0.0.0.0:5051</span><br><span class="line">chdir = /vagrant/images_check</span><br><span class="line">wsgi-file = /vagrant/images_check/uwsgi_entry.py</span><br><span class="line">callable = app</span><br><span class="line">processes = 4</span><br><span class="line">;harakiri = 30</span><br><span class="line">log-format = %(addr) - %(user) [%(ltime)] &quot;%(method) %(uri) %(proto)&quot; %(status) %(size) &quot;%(referer)&quot; &quot;%(uagent)&quot; %(msecs)ms</span><br></pre></td></tr></table></figure></p>
<p>而算法服务初始化，在入口出使用了queue去初始化，本来的目的是使多个进程都去同一个queue里获取算法服务的实例<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">q = Queue() </span><br><span class="line">for i in range(multiprocessing.cpu_count()):</span><br><span class="line">    bqc = CheckImage()</span><br><span class="line">    q.put(bqc)</span><br></pre></td></tr></table></figure></p>
<p>然而发现，运行之后，只有一个进程是能正确运行的，其他进程会阻塞在tf.session.run无法返回</p>
<h1 id="问题跟踪"><a href="#问题跟踪" class="headerlink" title="问题跟踪"></a>问题跟踪</h1><ol>
<li>因为在uwsgi中，工作进程是fork()主进程，获得了一个主进程“拷贝”的内存，所以每个进程都会有一个queue。</li>
<li><p>tensorflow不是进程安全的，所以上面“拷贝”内存的操作，可能倒是tensorflow hang了。<br>在tensorflow issue有类似的提问，<a href="https://github.com/tensorflow/tensorflow/issues/2448" target="_blank" rel="noopener">Session got stuck after fork</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">The in-process session (i.e. tf.Session() with no arguments) is not designed to be fork()-safe. If you want to share a set of devices between multiple processes, create a tf.train.Server in one process, and create sessions that connect to that server (with tf.Session(&quot;grpc://...&quot;)) in the other processes.</span><br></pre></td></tr></table></figure>
</li>
<li><p>这篇文章中提到<a href="https://www.cnblogs.com/haolujun/p/9778939.html" target="_blank" rel="noopener">机器学习web服务化实战：一次吐血的服务化之路</a>，的方法，在gunicorn的配置中实例化算法服务，gunicorn可以保证配置文件中的代码只运行一次。同时利用gc.freeze()把截止到当前的所有对象放入持久化区域，不进行回收，从而model占用的内存不会被copy-on-write。但是按照这个方法发现这个实例依然在fork的时候被copy了。</p>
</li>
</ol>
<h1 id="问题解决"><a href="#问题解决" class="headerlink" title="问题解决"></a>问题解决</h1><ol>
<li><p>方案一：改成了在每个进程初始化之后，初始化一个算法服务实例，根据cpu核数配置uwsgi工作进程数量</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">@app.before_first_request</span><br><span class="line">def first_quest():</span><br><span class="line">    q = Queue()</span><br><span class="line">    for i in range(1):</span><br><span class="line">    bqc = CheckImage()</span><br><span class="line">    q.put(bqc)</span><br></pre></td></tr></table></figure>
</li>
<li><p>方案二；<br> 使用redis/mc等中间件。但是有可能有序列化失败的问题。</p>
</li>
<li>使用tensorflow server</li>
</ol>
<h1 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h1><p>在gunicron中，配置preload_app = True是可以预加载资源的，但是fork工作进程还是可能出现坑。</p>
<p>参考:<br><a href="https://github.com/tensorflow/tensorflow/issues/2448" target="_blank" rel="noopener">Session got stuck after fork</a><br><a href="https://stackoverflow.com/questions/49227958/how-to-serve-tensorflow-model-using-flaskuwsgi" target="_blank" rel="noopener">How to serve tensorflow model using flask+uwsgi?</a><br><a href="https://www.cnblogs.com/haolujun/p/9778939.html" target="_blank" rel="noopener">机器学习web服务化实战：一次吐血的服务化之路</a><br><a href="http://timd.cn/fork-safety-and-thread-safety/" target="_blank" rel="noopener">fork-safe和thread-safe简介</a><br><a href="https://www.crifan.com/flask_gunicorn_multiple_process_worker_share_data_or_singleton/" target="_blank" rel="noopener">【已解决】Flask的gunicorn中多进程多worker如何共享数据或单实例</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://angelteng.github.io/blog/blog/2019/04/28/使用多进程服务器gunicorn中多线程问题/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Angel Teng">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://angelteng.github.io/blog/images/angel.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Code war of Angel">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/blog/2019/04/28/使用多进程服务器gunicorn中多线程问题/" itemprop="url">使用多进程服务器gunicorn中多线程问题</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-04-28T14:49:15+08:00">
                2019-04-28
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/blog/categories/后端/" itemprop="url" rel="index">
                    <span itemprop="name">后端</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="问题描述："><a href="#问题描述：" class="headerlink" title="问题描述："></a>问题描述：</h1><p>场景：<br>gunicorn + flask<br>gunicorn.conf:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">worker = 1  # 1个工作进程</span><br><span class="line">worker_class = &quot;geventwebsocket.gunicorn.workers.GeventWebSocketWorker&quot; # 因为使用了websocket</span><br></pre></td></tr></table></figure></p>
<p>在flask 入口处新增了一个子线程做redis的监听工作<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">import threading</span><br><span class="line">def listen_redis():</span><br><span class="line">    while True:</span><br><span class="line">        print(threading.currentThread())</span><br><span class="line">        .....</span><br><span class="line">        print(&apos;get redis&apos;)</span><br><span class="line">t = threading.Thread(target=listen_redis)</span><br><span class="line">t.start()</span><br></pre></td></tr></table></figure></p>
<p>问题1: 在使用gunicron运行的时候，发现子进程也运行了listen_redis的循环。<br>问题2: 同时由两个线程进行while true的操作，发现有时候一个while true断了再也不工作了。</p>
<h1 id="问题跟踪："><a href="#问题跟踪：" class="headerlink" title="问题跟踪："></a>问题跟踪：</h1><p>在查看gunicron的源码可以发现：<br>/venv/lib/python3.x/site-packages/gunicorn/arbiter.py<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># line: 575</span><br><span class="line">def spawn_worker(self):</span><br><span class="line">    self.worker_age += 1</span><br><span class="line">    worker = self.worker_class(self.worker_age, self.pid, self.LISTENERS,</span><br><span class="line">                               self.app, self.timeout / 2.0,</span><br><span class="line">                               self.cfg, self.log)</span><br><span class="line">    self.cfg.pre_fork(self, worker)</span><br><span class="line">    pid = os.fork()  #是在fork之后出现的“多余的子线程”</span><br><span class="line">    if pid != 0:</span><br><span class="line">        worker.pid = pid</span><br><span class="line">        self.WORKERS[pid] = worker</span><br><span class="line">        return pid</span><br></pre></td></tr></table></figure></p>
<p>通过print(threading.currentThread())可以看到log：<br>主进程的循环打印出来：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;Thread(Thread-2, started 140048726495560)&gt;</span><br></pre></td></tr></table></figure></p>
<p>而子进程的循环打印出来的是：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;_DummyThread(DummyThread-4, started daemon 140048726495560)&gt;</span><br></pre></td></tr></table></figure></p>
<p>可以确定的是，多了一个不是由threading创建的“虚拟线程”</p>
<p>然后查看gunicron对线程做了什么的时候发现<a href="https://github.com/benoitc/gunicorn/issues/1836" target="_blank" rel="noopener">这个问题</a><br>虽然不是同一个问题，但是这个说到了 monkey_patch对threading做了补丁<br>然后发现在 __init__.py 使用了猴子补丁，是为了websocket，使用了geventwebsocket模式，详情可以看<a href="https://flask-socketio.readthedocs.io/en/latest/#gunicorn-web-server" target="_blank" rel="noopener">flask-socketio文档</a><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">If eventlet or gevent are used, then monkey patching the Python standard library is normally required to force the message queue package to use coroutine friendly functions and classes.</span><br></pre></td></tr></table></figure></p>
<p>然后把猴子补丁改成：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">from gevent import monkey</span><br><span class="line">monkey.patch_all(thread=False)</span><br></pre></td></tr></table></figure></p>
<p>之后，发现“虚拟线程”没有被创建了。<br>但是偶尔会有下面报错，不影响正常功能，暂时不知道原因：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Exception ignored in: &lt;module &apos;gevent.threading&apos; from &apos;/demo/venv/lib/python3.5/site-packages/gevent/threading.py&apos;&gt;</span><br><span class="line">AttributeError: module &apos;gevent.threading&apos; has no attribute &apos;_after_fork&apos;</span><br></pre></td></tr></table></figure></p>
<h1 id="解析"><a href="#解析" class="headerlink" title="解析"></a>解析</h1><ol>
<li>首先明确的是，os.fork()创建出来对子进程并不会继承父进程的子线程。在<a href="http://linux.die.net/man/2/fork" target="_blank" rel="noopener">fork(2)-Linux Man Page</a>，中的描述：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">The child process is created with a single thread--the one that called fork(). The entire virtual address space of the parent is replicated in the child, including the states of mutexes, condition variables, and other pthreads objects; the use of pthread_atfork(3) may be helpful for dealing with problems that this can cause.</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>也就是说，在Linux中，fork的时候只复制当前线程到子进程。</p>
<ol start="2">
<li><p>那么，monkey_patch究竟做了什么?<br>monkeypatch修改了threading标准库中的_start_new_thread方法, Condition类等，创建了一个greenlet而不是真正的线程，然后就会在fork的时候被复制了。因此，也可以在gunicron的配置文件中，在on_starting的hook中创建真正的线程。<br>gevent是第三方库，通过greenlet实现协程，其基本思想是：当一个greenlet遇到IO操作时，比如访问网络，就自动切换到其他的greenlet，等到IO操作完成，再在适当的时候切换回来继续执行。由于IO操作非常耗时，经常使程序处于等待状态，有了gevent为我们自动切换协程，就保证总有greenlet在运行，而不是等待IO。<br>事实上，gunicron在使用gevent的时候，已经monkey patch了一次，如果patch多次，将会求多次中参数为True的并集。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># venv/lib/python3.5/site-packages/gunicorn/workers/ggevent.py:65</span><br><span class="line">def patch(self):</span><br><span class="line">from gevent import monkey</span><br><span class="line">monkey.noisy = False</span><br><span class="line"></span><br><span class="line"># if the new version is used make sure to patch subprocess</span><br><span class="line">if gevent.version_info[0] == 0:</span><br><span class="line">    monkey.patch_all()  # 默认值socket=True, dns=True, time=True, select=True, thread=True, os=True, ssl=True， httplib=False, subprocess=True, sys=False, aggressive=True, Event=False, builtins=True, signal=True</span><br><span class="line">else:</span><br><span class="line">    monkey.patch_all(subprocess=True)</span><br></pre></td></tr></table></figure>
</li>
<li><p>问题2: 从gevent的<a href="http://sdiehl.github.io/gevent-tutorial/" target="_blank" rel="noopener">文档</a>，可以知道，同一时间，只能有一个greenlet在运行，所以如果一个greenlet阻塞了，另一个greentlet就不可能运行，可以通过在while true末尾添加gevent.sleep(0.1)，把控制权（有可能）交给另外一个greenlet。</p>
</li>
</ol>
<h1 id="最终方案："><a href="#最终方案：" class="headerlink" title="最终方案："></a>最终方案：</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"># 方案一：阻塞事件使用线程</span><br><span class="line">from gevent import monkey</span><br><span class="line">monkey.patch_all(thread=False)</span><br><span class="line"></span><br><span class="line">from threading</span><br><span class="line">ta = threading.Thread(target=task)</span><br><span class="line">ta.start</span><br><span class="line"></span><br><span class="line">while true:</span><br><span class="line">    ....</span><br><span class="line">    # gevent.sleep(0.1)</span><br><span class="line"></span><br><span class="line"># 方案二：阻塞事件使用进程</span><br><span class="line">from gevent import monkey</span><br><span class="line">monkey.patch_all()</span><br><span class="line"></span><br><span class="line">from multiprocess import Process</span><br><span class="line">p = Process(target=task)</span><br><span class="line">p.start()</span><br><span class="line"></span><br><span class="line">while true:</span><br><span class="line">    ...</span><br></pre></td></tr></table></figure>
<p>参考:<br><a href="https://www.cnblogs.com/liyuan989/p/4279210.html" target="_blank" rel="noopener">谨慎使用多线程中的fork</a><br><a href="https://segmentfault.com/a/1190000013096677" target="_blank" rel="noopener">eventlet 之 monkeypatch 带来的若干兼容性问题实例分析</a><br><a href="https://github.com/benoitc/gunicorn/issues/1056" target="_blank" rel="noopener">monkey.patch_all and gunicorn with more than 1 worker</a><br><a href="http://xiaorui.cc/2016/04/27/源码分析之gevent-monkey-patch_all实现原理/" target="_blank" rel="noopener">源码分析之gevent monkey.patch_all实现原理</a><br><a href="http://www.361way.com/python-gevent/5329.html" target="_blank" rel="noopener">python异步 I/O模块gevent</a><br><a href="https://www.liaoxuefeng.com/wiki/001374738125095c955c1e6d8bb493182103fac9270762a000/001407503089986d175822da68d4d6685fbe849a0e0ca35000" target="_blank" rel="noopener">gevent-廖雪峰</a><br><a href="https://github.com/Junnplus/blog/issues/9" target="_blank" rel="noopener">gunicorn源码解析</a><br><a href="http://xiaorui.cc/2017/02/16/深入理解uwsgi和gunicorn网络模型上/" target="_blank" rel="noopener">深入理解uwsgi和gunicorn网络模型[上]</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://angelteng.github.io/blog/blog/2019/04/25/Redis的性能/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Angel Teng">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://angelteng.github.io/blog/images/angel.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Code war of Angel">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/blog/2019/04/25/Redis的性能/" itemprop="url">Redis的性能</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-04-25T16:54:27+08:00">
                2019-04-25
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/blog/categories/缓存/" itemprop="url" rel="index">
                    <span itemprop="name">缓存</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><a href="https://angelteng.github.io/blog/2018/11/22/Redis原理/">Redis的基本数据结构</a></p>
<p>首先，众所周知，Redis是单线程的。</p>
<h1 id="有多快？"><a href="#有多快？" class="headerlink" title="有多快？"></a>有多快？</h1><p>Redis采用的是基于内存的采用的是单进程单线程模型的 KV 数据库，由C语言编写，官方提供的数据是可以达到100000+的QPS（每秒内查询次数）。<br><img src="0.png" alt="image.png"></p>
<h1 id="为什么快？"><a href="#为什么快？" class="headerlink" title="为什么快？"></a>为什么快？</h1><ol>
<li>完全基于内存，绝大部分请求是纯粹的内存操作，非常快速。数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1)；</li>
<li>数据结构简单，对数据操作也简单，Redis中的数据结构是专门进行设计的；</li>
<li>采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗；</li>
<li>使用<a href="https://angelteng.github.io/blog/2019/04/24/I-O操作模式/">多路I/O复用模型</a>，非阻塞IO；</li>
<li>使用底层模型不同，它们之间底层实现方式以及与客户端之间通信的应用协议不一样，Redis直接自己构建了VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求；</li>
</ol>
<h1 id="Redis的内存模型"><a href="#Redis的内存模型" class="headerlink" title="Redis的内存模型"></a>Redis的内存模型</h1><p>Redis的内存主要包括：对象内存+缓冲内存+自身内存+内存碎片。 </p>
<ol>
<li>对象内存<br> 对象内存是Redis内存中占用最大一块，存储着所有的用户的数据。Redis所有的数据都采用的是key-value型数据类型</li>
<li><p>缓冲内存<br> 主要包括：客户端缓冲、复制积压缓冲区、AOF缓冲区 </p>
<ul>
<li>客户端缓冲：普通的客户端的连接（大量连接），从客户端（主要是复制的时候，异地跨机房，或者主节点下有多个从节点），订阅客户端（发布订阅功能，生产大于消费就会造成积压） </li>
<li>复制积压缓冲：2.8版本之后提供的可重用的固定大小缓冲区用于实现部分复制功能，默认1MB，主要是在主从同步时用到。 </li>
<li>AOF缓冲区：持久化用的，会先写入到缓冲区，然后根据响应的策略向磁盘进行同步，消耗的内存取决于写入的命令量和重写时间，通常很小。</li>
</ul>
</li>
<li><p>内存碎片<br> 目前可选的分配器有jemalloc、glibc、tcmalloc默认jemalloc<br> 出现高内存碎片问题的情况：大量的更新操作，比如append、setrange；大量的过期键删除，释放的空间无法得到有效利用<br> 解决办法：数据对齐，安全重启（高可用/主从切换）。</p>
</li>
<li>自身内存<br> 主要指AOF/RDB重写时Redis创建的子进程内存的消耗，Linux具有写时复制技术（copy-on-write），父子进程会共享相同的物理内存页，当父进程写请求时会对需要修改的页复制出一份副本来完成写操作。</li>
</ol>
<h1 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h1><ul>
<li>单进程多线程模型：MySQL、Memcached、Oracle</li>
<li>多进程模型：Oracle</li>
</ul>
<p>参考：<br><a href="https://juejin.im/entry/5b7cfe976fb9a01a13366d95" target="_blank" rel="noopener">Redis是单线程的，但Redis为什么这么快？</a><br><a href="https://juejin.im/entry/5b93ce4d5188255c48349316" target="_blank" rel="noopener">理解Redis的内存</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/blog/page/2/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/blog/">1</a><a class="page-number" href="/blog/page/2/">2</a><span class="page-number current">3</span><a class="page-number" href="/blog/page/4/">4</a><span class="space">&hellip;</span><a class="page-number" href="/blog/page/8/">8</a><a class="extend next" rel="next" href="/blog/page/4/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="https://angelteng.github.io/blog/images/angel.jpg" alt="Angel Teng">
            
              <p class="site-author-name" itemprop="name">Angel Teng</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/blog/archives/">
              
                  <span class="site-state-item-count">80</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/blog/category/index.html">
                  <span class="site-state-item-count">14</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/blog/tags/index.html">
                  <span class="site-state-item-count">32</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Angel Teng</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/blog/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/blog/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/blog/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/blog/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/blog/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/blog/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/blog/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/blog/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/blog/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  


  

  

</body>
</html>
