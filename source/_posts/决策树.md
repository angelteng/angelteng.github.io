---
title: 决策树
date: 2019-05-23 17:55:30
tags:
- 机器学习
categories: 机器学习
---
1. 决策树算法的核心是要解决两个问题: 
    - 如何从数据表中找出最佳节点和最佳分枝? 
    - 如何让决策树停止生长，防止过拟合?
2. 流程：
    - 计算全部特征的不纯度
    - 选取不纯度指标最优的特征来分化
    - 在第一个特征分支下，计算全部特征不纯度
    - 选取不纯度指标最优的特征继续分化
3. sklearn中使用
```
from sklearn import tree
tree.DecisionTreeClassifier:分类树
tree.DecisionTreeRegressor:回归树
tree.export_graphviz:将生成的决策树导出为DOT格式，画图专用
tree.ExtraTreeClassifier:高随机版本的分类树
tree.ExtraTreeRegressor:高随机版本的回归树
```
4. 重要参数
    - criterion: 不纯度的计算方法（不纯度越低、拟合效果越好）
        - entropy 信息熵
        - gini    基尼系数（默认）
    - random_state: 随机模式，高纬度下随机性更明显
        - None （默认）
        - 任意整数
    - splitter： 随机选项
        - best： 优先选择更重要的特征进行分支
        - random： 分支随机（防止过拟合）
5. 剪枝参数
在不加限制的情况下，一棵决策树会生长到衡量不纯度的指标最优，或者没有更多的特征可用为止，这样的决策树往往会过拟合。
    - max_depth: 限制最大深度
    - min_samples_leaf：一个节点在分枝后的每个子节点都必须包含至少min_samples_leaf个训练样本
    - min_samples_split: 一个分支至少含有min_samples_split个训练样本
    - max_features: 限制分枝时考虑的特征个数 
    - min_impurity_decrease: 限制信息增益的大小
6. 目标权重参数
    - class_weight：均衡标签样本的权重
    - min_ weight_fraction_leaf：基于权重的剪枝参数
6. 确定最优参数：
    - 学习曲线


参考
[菜菜的机器学习sklearn课堂](http://edu.cda.cn/course/982/tasks)
